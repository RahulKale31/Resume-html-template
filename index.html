<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Resume</title>
</head>
<body>
    <h1>Rahul Kale</h1>
    <img src="./Assests/profile photo.png" height="100"/>
    <br/>
    <h2>Summary</h2>
    <p>Detail-oriented and innovative Data Engineer with hands-on
        experience in developing and optimizing data pipelines on
        AWS. Proven ability to collaborate with stakeholders,
        gather requirements, and deliver solutions that enhance
        operational efficiency and reduce processing time. Adept in
        using Terraform for Infrastructure as Code (IAC) and
        proficient in Python and SQL.</p>
    <hr>
    <h2>Education</h2>
    <p>B.E.(2019)</p>
    <p>Savitribai Phule Pune University</p>
    <hr>
    <h2>Work experience</h2>
    <ul>
        <li>
    <h3>Jan 2024 - Present</h3>
    <h4>Data Engineer</h4>
    <h4>Tiger Analytics</h4>
    <h5>MMX Project</h5>
    <p> Data Management:<br/>
        Maintain and optimize Athena and Redshift tables, ensuring
        data integrity and accessibility.
        Oversee the Marketing Mix Datalake, tailoring data solutions to
        align with business needs.
        Collaboration and Quality Assurance:
        Work closely with business teams to conduct data quality
        checks, ensuring data accuracy and reliability.
        Collaborate with stakeholders to understand data requirements
        and incorporate new modules into the pipeline.
        Maintain and enhance existing data pipelines to adapt to new
        business needs and technological advancements.</p>
    <h5>SOTA Project</h5>
    <p>Infrastructure as Code:<br/>
        Create and manage Terraform scripts for provisioning
        Databricks resources in a project.
        Develop Terraform scripts for setting up various AWS
        resources for different projects, ensuring scalable and
        maintainable infrastructure.
        </p>
    </li>
    <li>
        <h3>Feb 2022 - Jan 2024</h3>
        <h4>Senior Software Engineer</h4>
        <h4>Tiger Analytics</h4>
        <h5>Global Omnichannel Project</h5>
        <ul>
            <p>Responsibilities:<br>
            <li>Developed and implemented a comprehensive data pipeline
            using AWS Step Functions to support a global omnichannel
            initiative.</li>
            <li>Collaborated with various stakeholders to gather and refine
            project requirements, ensuring alignment with business
            objectives.</li>
            <li>Authored efficient Python scripts and SQL statements to
            process and manipulate data, ensuring high performance and
            accuracy.</li>
            <li>Utilized Terraform for Infrastructure as Code (IAC) to manage
            AWS resources, ensuring consistent and repeatable
            deployments.</li>
            <li>Successfully completed deployments across development,
            User Acceptance Testing (UAT), and production environments,
            ensuring seamless integration and functionality.</li><br/>
            Key Achievements:<br>
            <li>Designed and deployed a robust data pipeline, enabling realtime data processing and improved data accuracy.
            Streamlined deployment processes using Terraform, reducing
            manual intervention and potential for errors.</li><br/>
            </p>
        </ul>        
        <h5>MMX Project</h5>
            Responsibilities:<br/>
            <ul>
                <li>Focused on optimizing AWS Glue jobs to enhance data
                processing efficiency.</li>
                <li>Conducted thorough analysis and implemented optimization
                techniques to reduce job execution time significantly.</li><br/>

                Key Achievements:<br/>
                <li>Achieved a reduction in job runtime by over 50%, leading to
                substantial improvements in processing speed and resource
                utilization.</li>
                <li>Delivered impactful changes that enhanced overall system
                performance and reduced operational costs.</li>
            </ul>
            
            

    </li>
    </ul>
    <hr>
    <h2>Certification</h2>
    <ul>
        <li>
            Databricks Certified Data Engineer Associate
        </li>
        <li>
            AWS Certified Solutions Architect â€“ Associate 
        </li>
        <li>
            Databricks Certified Associate Developer for Apache Spark 3.0
        </li>
        <li>
            Astronomer Certification DAG Authoring for Apache Airflow
        </li>
    </ul>
    <hr>
    <a href="./public/About_Me.html">About Me</a>
    <a href="./public/Hobbies.html">Hobbies</a>
</body>
</html>